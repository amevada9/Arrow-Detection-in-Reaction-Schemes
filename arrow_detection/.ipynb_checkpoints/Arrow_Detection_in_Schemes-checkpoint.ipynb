{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrow Detection in Schemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will be me working through how to detect arrows and their locations in different reaction schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math \n",
    "import imutils\n",
    "import json\n",
    "import copy\n",
    "import logging\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from skimage import io\n",
    "from skimage import filters\n",
    "from skimage.transform import rescale, resize\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from arrow_utils import arrow_average, arrow_centroid, line_mag, get_orientation, get_direction\n",
    "from image_utils import binary_close, binarize, binary_floodfill, skeletonize, pixel_ratio, skeletonize_area_ratio\n",
    "from contour_utils import split_contours, show_contours, show_all_contours, find_all_contours\n",
    "from detection import is_arrow, find_arrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful Links \n",
    "# https://scikit-learn.org/0.18/auto_examples/cluster/plot_face_segmentation.html\n",
    "# https://docs.opencv.org/master/d5/d45/tutorial_py_contours_more_functions.html\n",
    "# Load all the arrows that we have and their respective contours\n",
    "\n",
    "arrow_dir = os.path.join(os.getcwd(), 'arrows')\n",
    "list_arrows = sorted(os.listdir(arrow_dir))\n",
    "list_arrows = list_arrows[2:]\n",
    "arrows_contour = []\n",
    "for arrow in list_arrows:\n",
    "    arrows_image = cv2.imread(os.path.join(arrow_dir, arrow))\n",
    "    arrows_image = cv2.cvtColor(arrows_image, cv2.COLOR_BGR2GRAY)\n",
    "    _,threshold = cv2.threshold(arrows_image, 110, 255, cv2.THRESH_BINARY) \n",
    "    # Get all the contours on the image\n",
    "    arrow_cnts,_ = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n",
    "    for cnt in arrow_cnts:\n",
    "        approx = cv2.approxPolyDP(cnt, 0.01 * cv2.arcLength(cnt, True), True) \n",
    "        if len(approx) != 2.5:\n",
    "            arrows_contour.append(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the arrows that we have and their respective contours \n",
    "def load_arrows():\n",
    "    arrow_dir = os.path.join(os.getcwd(), 'arrows')\n",
    "    list_arrows = sorted(os.listdir(arrow_dir))\n",
    "    list_arrows = list_arrows[2:]\n",
    "    arrows_contour = []\n",
    "    for arrow in list_arrows:\n",
    "        arrows_image = cv2.imread(os.path.join(arrow_dir, arrow))\n",
    "        arrows_image = cv2.cvtColor(arrows_image, cv2.COLOR_BGR2GRAY)\n",
    "        _,threshold = cv2.threshold(arrows_image, 110, 255, cv2.THRESH_BINARY) \n",
    "        # Get all the contours on the image\n",
    "        arrow_cnts,_ = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n",
    "        for cnt in arrow_cnts:\n",
    "            approx = cv2.approxPolyDP(cnt, 0.01 * cv2.arcLength(cnt, True), True) \n",
    "            arrows_contour.append(cnt)\n",
    "            arrows_contour.append(approx)\n",
    "    return arrows_contour\n",
    "\n",
    "arrows_contour = load_arrows()\n",
    "#arrows_contour = arrows_contour[:43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Molecules and Chemical Structures\n",
    "def load_molecules():\n",
    "    struct_dir = os.path.join(os.getcwd(), 'random_molecules')\n",
    "    list_structs = sorted(os.listdir(struct_dir))\n",
    "    list_structs = list_structs[1:]\n",
    "    molecule_contours = []\n",
    "    for molecule in list_structs:\n",
    "        mol_image = cv2.imread(os.path.join(struct_dir, molecule))\n",
    "        mol_image = cv2.cvtColor(mol_image, cv2.COLOR_BGR2GRAY)\n",
    "        _,threshold = cv2.threshold(mol_image, 110, 255, cv2.THRESH_BINARY) \n",
    "        # Get all the contours on the image\n",
    "        mol_cnts,_ = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n",
    "        for cnt in mol_cnts:\n",
    "            molecule_contours.append(cnt)\n",
    "    return molecule_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_arrows(image):\n",
    "    ''' \n",
    "    Gets and draws arrow contours from the image onto the image\n",
    "    Need to work and making it save an image and/or getting the points so we \n",
    "    can get the centroid of the shape, thus knowing which side is products and which sides is reactants\n",
    "    \n",
    "    @PACKAGES:\n",
    "        - CV2: needed for contour extraction\n",
    "        - numpy: image array handling \n",
    "    @PARAM: \n",
    "        - image: a numpy array from a cv2 loaded image. Needs to be loaded by cv2 to allow for BGR conversion\n",
    "                 also will be converted from here\n",
    "    @RETURN:\n",
    "        - the image with the drawn in contours. Later will make it return the contours so that we can get the \n",
    "          \n",
    "    '''\n",
    "    list_contours = []\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _,threshold = cv2.threshold(image, 110, 255, cv2.THRESH_BINARY)\n",
    "    # Get all the contours on the image\n",
    "    cnts,_ = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n",
    "    for cnt in cnts: \n",
    "        area = cv2.contourArea(cnt)\n",
    "        # Shortlisting the regions based on their area.  \n",
    "        if area >= 80 and area < 900:\n",
    "            approx = cv2.approxPolyDP(cnt, 0.01 * cv2.arcLength(cnt, True), True) \n",
    "            # Reaction arrows have 5, 6, 7, or 8 sides so we will use that to narrow it down\n",
    "            # Also check if it is an arrow after that before drawing contours\n",
    "            #if len(approx) in [3, 5, 6, 7, 8, 9, 10]:\n",
    "            list_contours.append(cnt)\n",
    "                #list_contours.append(approx)\n",
    "    return list_contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction(image_name = None, image = None):\n",
    "    '''\n",
    "    Start of extraction pipeline, from image name to printed contours and \n",
    "    an image representation of the arrows identified. Will print all necessary \n",
    "    information for the user and will allow the user to see how each image is working\n",
    "    \n",
    "    Steps to Pipeline:\n",
    "    (1) Extract the arrow contours using find_arrow()\n",
    "    (2) Find the Averages of the points on the arrow\n",
    "    (3) Find the centroid (absolute middle) of the arrow\n",
    "        - (2) and (3) will be used to determine direction, \n",
    "          whichever side the average is away from the centroid is the direction\n",
    "          of the arrow pointing\n",
    "    (4) Find the orientation of the arrow (Horizontal or Vertical)\n",
    "    (5) Print all the information \n",
    "    (6) Show the image with the arrow contours \n",
    "    (7) Return the list of contours \n",
    "    \n",
    "    @PARAM:\n",
    "        - image_name: name of the image we want to run the pipeline on\n",
    "        - image: Could also supply just loaded Cv2 image, but then dont insert\n",
    "                the name of the image\n",
    "                \n",
    "        Examples:\n",
    "        \n",
    "        - If image is already loaded, use this format:\n",
    "            # Loading Image \n",
    "            image = cv2.imread({whatever directory})\n",
    "            extraction(image = diff_image)\n",
    "            \n",
    "            Note: This is preferred method, allows for image to be stored in \n",
    "            other directories and makes bulk detection easier\n",
    "            \n",
    "        - If you want to use the loading in the function, use this format:\n",
    "            extraction(image_name = 'image.png')\n",
    "            \n",
    "            Note: This format is not as effective, it is better to load the images ahead \n",
    "            of time especially if doing bulk conversions\n",
    "        \n",
    "    @RETURN:\n",
    "        - 0 if successful, 1 if there is an issue\n",
    "    '''\n",
    "    if image_name != None:\n",
    "        try:\n",
    "            image = cv2.imread(os.path.join(os.getcwd(), image_name))\n",
    "        except error:\n",
    "            print('Image name is not found, change directory or edit name. Function will stop now')\n",
    "            return -1, -1, -1, -1, -1\n",
    "    # Get the arrow contours and then get the necessary information from it\n",
    "    arrow_contours = find_arrows(image)\n",
    "    #If we dont find any arrows, return a message\n",
    "    if len(arrow_contours) == 0:\n",
    "        print(\"No arrows were found in the image\")\n",
    "        io.imshow(image)\n",
    "        return -1, -1, -1, -1, -1\n",
    "    print('Number of Contours: ', len(arrow_contours), '\\n')\n",
    "    averages = arrow_average(arrow_contours)\n",
    "    centroids = arrow_centroid(arrow_contours)\n",
    "    orientation = get_orientation(arrow_contours)\n",
    "    direction = get_direction(arrow_contours)\n",
    "#     for contour in range(len(arrow_contours)):\n",
    "#         print('Arrow Contour ' + str(contour + 1) + ': \\n \\n', arrow_contours[contour], '\\n\\n')\n",
    "    \n",
    "    print('Arrow Average Points:', averages, '\\n')\n",
    "    print('Arrow Centroid Points: ', centroids, '\\n')\n",
    "    for i in range(len(orientation)):\n",
    "        print('Arrow ' + str(i + 1) + ' Orientation: ', orientation[i])\n",
    "    print()\n",
    "    print(direction)\n",
    "    print()\n",
    "    io.imshow(show_contours(np.copy(image), arrow_contours))\n",
    "    return arrow_contours, averages, centroids, orientation, direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    ''' \n",
    "    Function that creates the Convolutional Neural Network that we need.\n",
    "    Has 6 convolutional layers, and 2 flattened layers at the end for binary\n",
    "    classification. Uses a binary crossentropy loss function, and a RMSprop \n",
    "    optimizer with a learning rate of 0.001. After 8 training epochs has an accuracy of \n",
    "    0.9427. Can definitly add more contours if needed later \n",
    "    \n",
    "    Summary:\n",
    "    Model: \"Sequential\"\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                 Output Shape              Param #   \n",
    "    =================================================================\n",
    "    conv2d (Conv2D)              (None, 498, 498, 16)      448       \n",
    "    _________________________________________________________________\n",
    "    max_pooling2d (MaxPooling2D) (None, 249, 249, 16)      0         \n",
    "    _________________________________________________________________\n",
    "    conv2d_1 (Conv2D)            (None, 247, 247, 32)      4640      \n",
    "    _________________________________________________________________\n",
    "    max_pooling2d_1 (MaxPooling2 (None, 123, 123, 32)      0         \n",
    "    _________________________________________________________________\n",
    "    conv2d_2 (Conv2D)            (None, 121, 121, 64)      18496     \n",
    "    _________________________________________________________________\n",
    "    max_pooling2d_2 (MaxPooling2 (None, 60, 60, 64)        0         \n",
    "    _________________________________________________________________\n",
    "    conv2d_3 (Conv2D)            (None, 58, 58, 64)        36928     \n",
    "    _________________________________________________________________\n",
    "    max_pooling2d_3 (MaxPooling2 (None, 29, 29, 64)        0         \n",
    "    _________________________________________________________________\n",
    "    conv2d_4 (Conv2D)            (None, 27, 27, 64)        36928     \n",
    "    _________________________________________________________________\n",
    "    max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n",
    "    _________________________________________________________________\n",
    "    conv2d_5 (Conv2D)            (None, 11, 11, 64)        36928     \n",
    "    _________________________________________________________________\n",
    "    max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
    "    _________________________________________________________________\n",
    "    flatten (Flatten)            (None, 1600)              0         \n",
    "    _________________________________________________________________\n",
    "    dense (Dense)                (None, 256)               409856    \n",
    "    _________________________________________________________________\n",
    "    dense_1 (Dense)              (None, 1)                 257       \n",
    "    =================================================================\n",
    "    Total params: 544,481\n",
    "    Trainable params: 544,481\n",
    "    Non-trainable params: 0\n",
    "    _________________________________________________________________\n",
    "    \n",
    "    @RETURN: the compiled version of this model. Still needs fitting and training later \n",
    "             (8-10 epochs, should take about 20-25 min)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    # First Convolution\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(500, 500, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Second Convolution\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Third Convolution \n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    # The fourth convolution\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    # The fifth convolution\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    # Sixth Convolution (Wow)\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    # Flatten and feed to a normal DNN\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation= 'relu'))\n",
    "    # Gives us value between 0 and 1 for what it thinks\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    # Use binary crossentropy loss function to create binary classifer\n",
    "    loss_fn = 'binary_crossentropy'\n",
    "    opt = RMSprop(lr = 0.001)\n",
    "    model.compile(optimizer = opt, loss= loss_fn, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(image, model):\n",
    "    '''\n",
    "    Full extraction pipeline, from image name to printed contours and \n",
    "    an image representation of the arrows identified. Will print all necessary \n",
    "    information for the user and will allow the user to see how each image is working\n",
    "    \n",
    "    Steps to Pipeline:\n",
    "    (1) Extract the arrow contours using find_arrow()\n",
    "    (2) Find the Averages of the points on the arrow\n",
    "    (3) Find the centroid (absolute middle) of the arrow\n",
    "        - (2) and (3) will be used to determine direction, \n",
    "          whichever side the average is away from the centroid is the direction\n",
    "          of the arrow pointing\n",
    "    (4) Find the orientation of the arrow (Horizontal or Vertical)\n",
    "    (5) Print all the information \n",
    "    (6) Show the image with the arrow contours \n",
    "    (7) Return the list of contours \n",
    "    \n",
    "    Steps for Final Pipeline:\n",
    "    (1) Use previous pipeline to get to get all the potential arrows\n",
    "    (2) Split the contours, and create padded images for them\n",
    "    (3) Cache and reload them in correct format\n",
    "    (4) Use the CNN to filter the potential arrows into the real arrows\n",
    "    \n",
    "    @PARAM:\n",
    "        - image: Could also supply just loaded Cv2 image, but then dont insert\n",
    "                the name of the image\n",
    "        - model: Neural network that we want to use to predict. Needs to be fitted and created\n",
    "                 before hand. \n",
    "                \n",
    "        Examples:\n",
    "        \n",
    "        - If image is already loaded, use this format:\n",
    "            # Loading Image \n",
    "            image = cv2.imread({whatever directory})\n",
    "            pipeline(image = diff_image)\n",
    "            \n",
    "            Note: This is preferred method, allows for image to be stored in \n",
    "            other directories and makes bulk detection easier\n",
    "\n",
    "    @RETURN:\n",
    "        - final_contours: contours of the arrows\n",
    "        - final_directions: directions of the arrows\n",
    "        - final_centroids: centroids of the arrow (can be used with direction to determine reaction order)\n",
    "        \n",
    "        Note: Also prints these information out, and along with the original pipeline information. \n",
    "              If there are no errors from pipeline, then the function will break.\n",
    "    '''\n",
    "    # Load all the information\n",
    "    arrow_contours, averages, centroids, orientation, direction = extraction(image = image)\n",
    "    if arrow_contours == -1:\n",
    "        return -1, -1, -1\n",
    "    # Split contours for padding \n",
    "    split = split_contours(arrow_contours)\n",
    "    split = np.array(split)\n",
    "    # Because of how CNN was trained, we will save images to load into model\n",
    "    # Will all be deleted later and does not adversely affect runtime\n",
    "    try:\n",
    "        os.makedirs('Images_Cache')\n",
    "    except FileExistsError:\n",
    "        os.rmdir(\"Images_Cache\")\n",
    "        os.makedirs('Images_Cache')\n",
    "\n",
    "    cache_dir = os.path.join(os.getcwd(), 'Images_Cache')\n",
    "    for i in range(len(split)):\n",
    "        image = pad_image(split[i])\n",
    "        io.imsave(os.path.join(cache_dir, 'testcon' + str(i + 1) + '.png'), image)\n",
    "    cache = sorted(os.listdir(cache_dir))\n",
    "    # Read the padded images\n",
    "    padded_images = []\n",
    "    for item in cache:\n",
    "        item_path = os.path.join(cache_dir, item)\n",
    "        read_image = cv2.imread(item_path)\n",
    "        padded_images.append(read_image)\n",
    "        os.remove(item_path)\n",
    "    # Remove cache \n",
    "    os.rmdir(\"Images_Cache\")\n",
    "    \n",
    "    # Prepare list of padded images for the model and predict\n",
    "    padded_images = np.array(padded_images)\n",
    "    padded_images = padded_images / 255.0\n",
    "    padded_images = padded_images.reshape(padded_images.shape[0], 500, 500, 3)\n",
    "    results = model.predict(padded_images)\n",
    "    \n",
    "    # Contours that are given a sigmoid score between 0 and 1\n",
    "    # 0 is a perfect arrow and 1 is absolutly not. For now the barrier is\n",
    "    # 0.1 for the barrier for the arrow. We will store the indicies in the \n",
    "    # final_contours array\n",
    "    final_contours = []\n",
    "    conf = []\n",
    "    for contour in range(len(results)):\n",
    "        if results[contour] < 0.1:\n",
    "            final_contours.append(contour)\n",
    "            conf.append(results[contour])\n",
    "    final_centroids = []\n",
    "    final_averages = []\n",
    "    final_directions = []\n",
    "    # Add all the information about the arrows that passed the model\n",
    "    for idx in final_contours:\n",
    "        final_centroids.append(centroids[idx])\n",
    "        final_averages.append(averages[idx])\n",
    "        final_directions.append(direction['Arrow ' + str(idx + 1)])\n",
    "    \n",
    "    # Print all the logical informatio (might need to delete later)\n",
    "    print()\n",
    "    print(\"Final Contours Index: \", final_contours)\n",
    "    print()\n",
    "    print(\"Confidence: \", conf)\n",
    "    print()\n",
    "    print('Final Centroids', final_centroids)\n",
    "    print()\n",
    "    print('Final Averages', final_averages)\n",
    "    print()\n",
    "    print('Final Directions', final_directions)\n",
    "    print()\n",
    "    return final_contours, final_directions, final_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrows Length:  1115\n",
      "Not Arrows Length:  1498\n"
     ]
    }
   ],
   "source": [
    "# Load Data to train Neural Network\n",
    "class_names = ['Arrow', 'Not Arrow']\n",
    "arrow_set = os.path.join(os.getcwd(), 'padded_arrows', '1arrows')\n",
    "not_arrows = os.path.join(os.getcwd(), 'padded_arrows', '1notArrows')\n",
    "arrow_ims = sorted(os.listdir(arrow_set))[2:]\n",
    "not_arrow_ims = sorted(os.listdir(not_arrows))[2:]\n",
    "print('Arrows Length: ', len(arrow_ims))\n",
    "print('Not Arrows Length: ', len(not_arrow_ims))\n",
    "training_set = arrow_ims + not_arrow_ims\n",
    "labels = []\n",
    "for i in range(len(arrow_ims) + len(not_arrow_ims)):\n",
    "    if i < len(arrow_ims):\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_images = []\n",
    "# for img in arrow_ims:\n",
    "#     loaded_im = cv2.imread(os.path.join(arrow_set, img))\n",
    "#     if loaded_im.shape == (500, 500, 3):\n",
    "#         training_images.append(loaded_im)\n",
    "#     else:\n",
    "#         print('Arrow: ' + img)\n",
    "# for img in not_arrow_ims:\n",
    "#     loaded_im = cv2.imread(os.path.join(not_arrows, img))\n",
    "#     if isinstance(loaded_im, type(None)):\n",
    "#         print(\"None Type Object: \", img)\n",
    "#     elif loaded_im.shape != (500, 500, 3):\n",
    "#         print('Wrong Shape: ', img)\n",
    "#     else:\n",
    "#         training_images.append(loaded_im)\n",
    "# training_images = np.array(training_images)\n",
    "# training_images = training_images / 255.0\n",
    "# training_images = training_images.reshape(training_images.shape[0], 500, 500, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 498, 498, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 249, 249, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 247, 247, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 123, 123, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 121, 121, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 58, 58, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 27, 27, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               409856    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 544,481\n",
      "Trainable params: 544,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the model that is needed and trained and work from here. \n",
    "# No need to recreate every iteration \n",
    "model = keras.models.load_model('model2_new')\n",
    "model2 = keras.models.load_model('epoch8_model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(training_images, labels, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-52193af91792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdiff_reactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'testing_set'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sample_reactions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdiff_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_reactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Page10-1.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_cons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-39f280bf8c9d>\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(image, model)\u001b[0m\n\u001b[1;32m     48\u001b[0m     '''\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Load all the information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0marrow_contours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marrow_contours\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-e4dc7bb59c27>\u001b[0m in \u001b[0;36mextraction\u001b[0;34m(image_name, image)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Get the arrow contours and then get the necessary information from it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0marrow_contours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_arrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;31m#If we dont find any arrows, return a message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrow_contours\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SURF/surf-nlp-osr/arrow_detection/detection.py\u001b[0m in \u001b[0;36mfind_arrows\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     68\u001b[0m     '''\n\u001b[1;32m     69\u001b[0m     \u001b[0mlist_contours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m110\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# Get all the contours on the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "diff_reactions = os.path.join(os.getcwd(), 'testing_set','sample_reactions')\n",
    "diff_image = cv2.imread(os.path.join(diff_reactions, 'Page10-1.png'))\n",
    "test_cons = pipeline(image = diff_image, model = model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-a268f52dc863>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlistdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_cons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-39f280bf8c9d>\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(image, model)\u001b[0m\n\u001b[1;32m     48\u001b[0m     '''\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Load all the information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0marrow_contours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marrow_contours\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-e4dc7bb59c27>\u001b[0m in \u001b[0;36mextraction\u001b[0;34m(image_name, image)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Get the arrow contours and then get the necessary information from it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0marrow_contours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_arrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;31m#If we dont find any arrows, return a message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrow_contours\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SURF/surf-nlp-osr/arrow_detection/detection.py\u001b[0m in \u001b[0;36mfind_arrows\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mPARAM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mNeeds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mby\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0mto\u001b[0m \u001b[0mallow\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mBGR\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                  \u001b[0malso\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mRETURN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdrawn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mLater\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mmake\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcontours\u001b[0m \u001b[0mso\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# testing on an example images \n",
    "test_dir = os.path.join(os.getcwd(), 'testing_set', 'test_sample_reactions')\n",
    "listdir = sorted(os.listdir(test_dir))[2:]\n",
    "image2 = io.imread(os.path.join(test_dir, listdir[2]))\n",
    "test_cons = pipeline(image = image2, model = model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3dda10e7db15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlist_reactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdiff_image2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_reactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcons1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff_image2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-39f280bf8c9d>\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(image, model)\u001b[0m\n\u001b[1;32m     48\u001b[0m     '''\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Load all the information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0marrow_contours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marrow_contours\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-e4dc7bb59c27>\u001b[0m in \u001b[0;36mextraction\u001b[0;34m(image_name, image)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Get the arrow contours and then get the necessary information from it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0marrow_contours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_arrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;31m#If we dont find any arrows, return a message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrow_contours\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/SURF/surf-nlp-osr/arrow_detection/arrow_utils.py\u001b[0m in \u001b[0;36mfind_arrows\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mNeeds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mby\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0mto\u001b[0m \u001b[0mallow\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mBGR\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                  \u001b[0malso\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mRETURN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdrawn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mLater\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mmake\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcontours\u001b[0m \u001b[0mso\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# arrows_image = io.imread(os.path.join(arrow_dir, list_arrows[3]))\n",
    "# arrow_image = binarize(arrows_image)\n",
    "# arrow_test = find_contours(arrows_image, 0.8)\n",
    "# io.imshow(show_contours(arrows_image, arrow_test))\n",
    "reactions = os.path.join(os.getcwd(), 'testing_set',\"ja00073a072_si_001_output\", 'images_with_boxes_dpi_100')\n",
    "list_reactions = sorted(os.listdir(reactions))\n",
    "diff_image2 = cv2.imread(os.path.join(reactions, list_reactions[4]))\n",
    "cons1 = pipeline(image = diff_image2, model = model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours:  81 \n",
      "\n",
      "[(299.3258426966292, 829.7752808988764), (470.9222222222222, 824.5888888888888), (533.7741935483871, 812.3225806451613), (307.90140845070425, 782.1760563380282), (475.5870967741935, 777.4580645161291), (64.73518518518519, 787.8851851851852), (504.47058823529414, 758.7310924369748), (110.33333333333333, 775.5300546448087), (530.7980769230769, 762.7307692307693), (361.83116883116884, 757.0), (414.03125, 768.0), (77.9375, 672.0), (494.2803738317757, 665.2990654205607), (349.0416666666667, 661.3333333333334), (201.42857142857142, 662.4732142857143), (97.92307692307692, 639.2857142857143), (247.92222222222222, 630.6), (540.0394736842105, 625.5), (396.4886363636364, 627.5113636363636), (208.95876288659792, 612.6907216494845), (360.15441176470586, 618.5955882352941), (497.6666666666667, 611.3953488372093), (60.84023668639053, 632.5562130177515), (523.2077922077922, 602.0519480519481), (552.8510638297872, 600.2021276595744), (115.28828828828829, 597.7747747747748), (527.047619047619, 557.063492063492), (216.8625, 532.375), (216.65822784810126, 514.8860759493671), (27.132530120481928, 513.8674698795181), (47.74193548387097, 489.35483870967744), (274.20512820512823, 468.20512820512823), (59.20987654320987, 469.17283950617286), (499.91011235955057, 465.1011235955056), (99.36666666666666, 448.43333333333334), (540.8739495798319, 430.38655462184875), (56.31122448979592, 426.2448979591837), (279.55434782608694, 414.1630434782609), (505.66359447004606, 422.7972350230415), (85.78977272727273, 418.4261363636364), (556.0805369127517, 396.26174496644296), (31.6, 344.7375), (565.0, 332.5), (481.1666666666667, 328.1904761904762), (31.7625, 327.05), (317.6, 310.8125), (31.175, 309.5125), (524.8775510204082, 270.2040816326531), (228.5909090909091, 268.90909090909093), (163.4262295081967, 236.8360655737705), (462.3787878787879, 234.8030303030303), (313.921875, 234.90625), (372.1761658031088, 252.5336787564767), (237.7663551401869, 235.30841121495328), (557.9896373056995, 236.7461139896373), (519.0251046025105, 232.0), (215.5944055944056, 221.2237762237762), (374.84705882352944, 210.75294117647059), (553.0, 195.5), (102.17821782178218, 236.75247524752476), (540.060606060606, 172.04545454545453), (469.5875, 133.825), (469.58024691358025, 113.91358024691358), (39.70967741935484, 61.67741935483871), (21.0, 61.9375), (414.8666666666667, 63.666666666666664), (302.55, 44.93333333333333), (180.34920634920636, 45.523809523809526), (458.04761904761904, 44.857142857142854), (557.2903225806451, 41.67741935483871), (495.741935483871, 37.32258064516129), (397.0810810810811, 38.21621621621622), (244.58024691358025, 37.93827160493827), (133.73142857142858, 51.902857142857144), (70.43147208121827, 40.796954314720814), (564.2215568862275, 45.053892215568865), (373.8719512195122, 38.4390243902439), (226.86507936507937, 44.24603174603175), (267.041095890411, 23.10958904109589), (150.18627450980392, 31.666666666666668), (533.0238907849829, 32.80204778156997)]\n",
      "Arrow Average Points: [(299.3258426966292, 829.7752808988764), (470.9222222222222, 824.5888888888888), (533.7741935483871, 812.3225806451613), (307.90140845070425, 782.1760563380282), (475.5870967741935, 777.4580645161291), (64.73518518518519, 787.8851851851852), (504.47058823529414, 758.7310924369748), (110.33333333333333, 775.5300546448087), (530.7980769230769, 762.7307692307693), (361.83116883116884, 757.0), (414.03125, 768.0), (77.9375, 672.0), (494.2803738317757, 665.2990654205607), (349.0416666666667, 661.3333333333334), (201.42857142857142, 662.4732142857143), (97.92307692307692, 639.2857142857143), (247.92222222222222, 630.6), (540.0394736842105, 625.5), (396.4886363636364, 627.5113636363636), (208.95876288659792, 612.6907216494845), (360.15441176470586, 618.5955882352941), (497.6666666666667, 611.3953488372093), (60.84023668639053, 632.5562130177515), (523.2077922077922, 602.0519480519481), (552.8510638297872, 600.2021276595744), (115.28828828828829, 597.7747747747748), (527.047619047619, 557.063492063492), (216.8625, 532.375), (216.65822784810126, 514.8860759493671), (27.132530120481928, 513.8674698795181), (47.74193548387097, 489.35483870967744), (274.20512820512823, 468.20512820512823), (59.20987654320987, 469.17283950617286), (499.91011235955057, 465.1011235955056), (99.36666666666666, 448.43333333333334), (540.8739495798319, 430.38655462184875), (56.31122448979592, 426.2448979591837), (279.55434782608694, 414.1630434782609), (505.66359447004606, 422.7972350230415), (85.78977272727273, 418.4261363636364), (556.0805369127517, 396.26174496644296), (31.6, 344.7375), (565.0, 332.5), (481.1666666666667, 328.1904761904762), (31.7625, 327.05), (317.6, 310.8125), (31.175, 309.5125), (524.8775510204082, 270.2040816326531), (228.5909090909091, 268.90909090909093), (163.4262295081967, 236.8360655737705), (462.3787878787879, 234.8030303030303), (313.921875, 234.90625), (372.1761658031088, 252.5336787564767), (237.7663551401869, 235.30841121495328), (557.9896373056995, 236.7461139896373), (519.0251046025105, 232.0), (215.5944055944056, 221.2237762237762), (374.84705882352944, 210.75294117647059), (553.0, 195.5), (102.17821782178218, 236.75247524752476), (540.060606060606, 172.04545454545453), (469.5875, 133.825), (469.58024691358025, 113.91358024691358), (39.70967741935484, 61.67741935483871), (21.0, 61.9375), (414.8666666666667, 63.666666666666664), (302.55, 44.93333333333333), (180.34920634920636, 45.523809523809526), (458.04761904761904, 44.857142857142854), (557.2903225806451, 41.67741935483871), (495.741935483871, 37.32258064516129), (397.0810810810811, 38.21621621621622), (244.58024691358025, 37.93827160493827), (133.73142857142858, 51.902857142857144), (70.43147208121827, 40.796954314720814), (564.2215568862275, 45.053892215568865), (373.8719512195122, 38.4390243902439), (226.86507936507937, 44.24603174603175), (267.041095890411, 23.10958904109589), (150.18627450980392, 31.666666666666668), (533.0238907849829, 32.80204778156997)] \n",
      "\n",
      "Arrow Centroid Points:  [(302.0, 827.0), (474.0, 821.5), (533.5, 812.5), (304.5, 784.0), (469.5, 780.0), (71.0, 790.0), (507.5, 760.5), (109.5, 774.5), (526.5, 761.5), (361.5, 757.5), (414.5, 768.0), (77.5, 672.0), (498.5, 664.0), (349.5, 662.0), (203.5, 661.0), (95.5, 637.0), (250.0, 628.5), (541.0, 626.5), (395.5, 628.0), (206.5, 611.5), (355.0, 621.0), (493.0, 609.0), (61.0, 631.5), (523.0, 601.0), (550.0, 600.5), (112.0, 599.5), (527.0, 557.0), (218.5, 532.5), (218.5, 515.0), (29.0, 514.5), (47.5, 489.5), (277.5, 465.0), (60.0, 469.5), (503.0, 462.5), (96.0, 447.0), (538.0, 431.5), (57.5, 429.0), (275.5, 414.0), (502.5, 425.0), (88.0, 418.5), (551.5, 398.5), (33.0, 345.0), (565.0, 332.5), (483.0, 328.5), (33.5, 327.5), (319.5, 311.0), (32.5, 309.5), (528.0, 269.0), (232.0, 265.5), (163.5, 236.5), (462.5, 234.5), (314.0, 234.5), (376.5, 249.0), (235.5, 234.0), (554.0, 235.0), (519.5, 229.0), (218.5, 221.5), (376.0, 208.5), (553.0, 195.5), (102.5, 237.0), (540.0, 171.5), (471.0, 134.0), (471.0, 114.5), (39.5, 61.5), (21.0, 61.5), (417.0, 63.5), (302.5, 45.0), (180.5, 45.5), (458.0, 44.5), (557.5, 41.5), (495.5, 37.5), (399.0, 39.5), (242.0, 39.5), (138.0, 49.0), (69.5, 41.5), (559.0, 41.0), (375.0, 41.5), (230.5, 42.0), (267.5, 21.0), (148.5, 32.0), (532.5, 30.5)] \n",
      "\n",
      "Arrow 1 Orientation:  Vertical\n",
      "Arrow 2 Orientation:  Horizontal\n",
      "Arrow 3 Orientation:  Vertical\n",
      "Arrow 4 Orientation:  Vertical\n",
      "Arrow 5 Orientation:  Vertical\n",
      "Arrow 6 Orientation:  Vertical\n",
      "Arrow 7 Orientation:  Vertical\n",
      "Arrow 8 Orientation:  Vertical\n",
      "Arrow 9 Orientation:  Vertical\n",
      "Arrow 10 Orientation:  Vertical\n",
      "Arrow 11 Orientation:  Vertical\n",
      "Arrow 12 Orientation:  Vertical\n",
      "Arrow 13 Orientation:  Vertical\n",
      "Arrow 14 Orientation:  Vertical\n",
      "Arrow 15 Orientation:  Vertical\n",
      "Arrow 16 Orientation:  Vertical\n",
      "Arrow 17 Orientation:  Vertical\n",
      "Arrow 18 Orientation:  Vertical\n",
      "Arrow 19 Orientation:  Vertical\n",
      "Arrow 20 Orientation:  Vertical\n",
      "Arrow 21 Orientation:  Vertical\n",
      "Arrow 22 Orientation:  Horizontal\n",
      "Arrow 23 Orientation:  Vertical\n",
      "Arrow 24 Orientation:  Vertical\n",
      "Arrow 25 Orientation:  Vertical\n",
      "Arrow 26 Orientation:  Vertical\n",
      "Arrow 27 Orientation:  Vertical\n",
      "Arrow 28 Orientation:  Horizontal\n",
      "Arrow 29 Orientation:  Horizontal\n",
      "Arrow 30 Orientation:  Horizontal\n",
      "Arrow 31 Orientation:  Vertical\n",
      "Arrow 32 Orientation:  Vertical\n",
      "Arrow 33 Orientation:  Vertical\n",
      "Arrow 34 Orientation:  Vertical\n",
      "Arrow 35 Orientation:  Vertical\n",
      "Arrow 36 Orientation:  Vertical\n",
      "Arrow 37 Orientation:  Vertical\n",
      "Arrow 38 Orientation:  Vertical\n",
      "Arrow 39 Orientation:  Vertical\n",
      "Arrow 40 Orientation:  Vertical\n",
      "Arrow 41 Orientation:  Vertical\n",
      "Arrow 42 Orientation:  Horizontal\n",
      "Arrow 43 Orientation:  Vertical\n",
      "Arrow 44 Orientation:  Horizontal\n",
      "Arrow 45 Orientation:  Horizontal\n",
      "Arrow 46 Orientation:  Horizontal\n",
      "Arrow 47 Orientation:  Horizontal\n",
      "Arrow 48 Orientation:  Vertical\n",
      "Arrow 49 Orientation:  Vertical\n",
      "Arrow 50 Orientation:  Horizontal\n",
      "Arrow 51 Orientation:  Horizontal\n",
      "Arrow 52 Orientation:  Horizontal\n",
      "Arrow 53 Orientation:  Vertical\n",
      "Arrow 54 Orientation:  Vertical\n",
      "Arrow 55 Orientation:  Vertical\n",
      "Arrow 56 Orientation:  Vertical\n",
      "Arrow 57 Orientation:  Vertical\n",
      "Arrow 58 Orientation:  Vertical\n",
      "Arrow 59 Orientation:  Vertical\n",
      "Arrow 60 Orientation:  Vertical\n",
      "Arrow 61 Orientation:  Vertical\n",
      "Arrow 62 Orientation:  Horizontal\n",
      "Arrow 63 Orientation:  Horizontal\n",
      "Arrow 64 Orientation:  Vertical\n",
      "Arrow 65 Orientation:  Vertical\n",
      "Arrow 66 Orientation:  Vertical\n",
      "Arrow 67 Orientation:  Horizontal\n",
      "Arrow 68 Orientation:  Horizontal\n",
      "Arrow 69 Orientation:  Horizontal\n",
      "Arrow 70 Orientation:  Vertical\n",
      "Arrow 71 Orientation:  Vertical\n",
      "Arrow 72 Orientation:  Vertical\n",
      "Arrow 73 Orientation:  Vertical\n",
      "Arrow 74 Orientation:  Vertical\n",
      "Arrow 75 Orientation:  Horizontal\n",
      "Arrow 76 Orientation:  Vertical\n",
      "Arrow 77 Orientation:  Vertical\n",
      "Arrow 78 Orientation:  Vertical\n",
      "Arrow 79 Orientation:  Horizontal\n",
      "Arrow 80 Orientation:  Vertical\n",
      "Arrow 81 Orientation:  Horizontal\n",
      "\n",
      "{'Arrow 1': 'Down', 'Arrow 2': 'Left', 'Arrow 3': 'Up', 'Arrow 4': 'Up', 'Arrow 5': 'Up', 'Arrow 6': 'Up', 'Arrow 7': 'Up', 'Arrow 8': 'Down', 'Arrow 9': 'Down', 'Arrow 10': 'Up', 'Arrow 11': 'Up', 'Arrow 12': 'Up', 'Arrow 13': 'Down', 'Arrow 14': 'Up', 'Arrow 15': 'Down', 'Arrow 16': 'Down', 'Arrow 17': 'Down', 'Arrow 18': 'Up', 'Arrow 19': 'Up', 'Arrow 20': 'Down', 'Arrow 21': 'Up', 'Arrow 22': 'Right', 'Arrow 23': 'Down', 'Arrow 24': 'Down', 'Arrow 25': 'Up', 'Arrow 26': 'Up', 'Arrow 27': 'Down', 'Arrow 28': 'Left', 'Arrow 29': 'Left', 'Arrow 30': 'Left', 'Arrow 31': 'Up', 'Arrow 32': 'Down', 'Arrow 33': 'Up', 'Arrow 34': 'Down', 'Arrow 35': 'Down', 'Arrow 36': 'Up', 'Arrow 37': 'Up', 'Arrow 38': 'Down', 'Arrow 39': 'Up', 'Arrow 40': 'Up', 'Arrow 41': 'Up', 'Arrow 42': 'Left', 'Arrow 43': 'Up', 'Arrow 44': 'Left', 'Arrow 45': 'Left', 'Arrow 46': 'Left', 'Arrow 47': 'Left', 'Arrow 48': 'Down', 'Arrow 49': 'Down', 'Arrow 50': 'Left', 'Arrow 51': 'Left', 'Arrow 52': 'Left', 'Arrow 53': 'Down', 'Arrow 54': 'Down', 'Arrow 55': 'Down', 'Arrow 56': 'Down', 'Arrow 57': 'Up', 'Arrow 58': 'Down', 'Arrow 59': 'Up', 'Arrow 60': 'Up', 'Arrow 61': 'Down', 'Arrow 62': 'Left', 'Arrow 63': 'Left', 'Arrow 64': 'Down', 'Arrow 65': 'Down', 'Arrow 66': 'Down', 'Arrow 67': 'Right', 'Arrow 68': 'Left', 'Arrow 69': 'Right', 'Arrow 70': 'Down', 'Arrow 71': 'Up', 'Arrow 72': 'Up', 'Arrow 73': 'Up', 'Arrow 74': 'Down', 'Arrow 75': 'Right', 'Arrow 76': 'Down', 'Arrow 77': 'Up', 'Arrow 78': 'Down', 'Arrow 79': 'Left', 'Arrow 80': 'Up', 'Arrow 81': 'Right'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon1.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon2.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon3.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon4.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon5.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon7.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon8.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon9.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon10.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon11.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon12.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon13.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon14.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon15.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon16.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon17.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon18.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon19.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon20.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon21.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon22.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon23.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon24.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon25.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon26.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon27.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon28.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon29.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon30.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon31.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon32.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon33.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon34.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon35.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon36.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon37.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon38.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon39.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon40.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon41.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon42.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon43.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon44.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon45.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon46.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon47.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon48.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon49.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon50.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon51.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon52.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon53.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon54.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon55.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon56.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon57.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon58.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon59.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon60.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon61.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon62.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon63.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon64.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon65.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon66.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon67.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon68.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon69.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon70.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon71.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon72.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon73.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon74.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon75.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon76.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon77.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon78.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon79.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon80.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "/Users/aryamevada/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: UserWarning: /Users/aryamevada/Documents/SURF/surf-nlp-osr/arrow_detection/Images_Cache/testcon81.png is a low contrast image\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Contours Index:  [2, 13, 15, 17, 18, 29, 33, 35, 50, 51, 52, 55, 80]\n",
      "\n",
      "Final Centroids [(533.5, 812.5), (349.5, 662.0), (95.5, 637.0), (541.0, 626.5), (395.5, 628.0), (29.0, 514.5), (503.0, 462.5), (538.0, 431.5), (462.5, 234.5), (314.0, 234.5), (376.5, 249.0), (519.5, 229.0), (532.5, 30.5)]\n",
      "\n",
      "Final Averages [(533.7741935483871, 812.3225806451613), (349.0416666666667, 661.3333333333334), (97.92307692307692, 639.2857142857143), (540.0394736842105, 625.5), (396.4886363636364, 627.5113636363636), (27.132530120481928, 513.8674698795181), (499.91011235955057, 465.1011235955056), (540.8739495798319, 430.38655462184875), (462.3787878787879, 234.8030303030303), (313.921875, 234.90625), (372.1761658031088, 252.5336787564767), (519.0251046025105, 232.0), (533.0238907849829, 32.80204778156997)]\n",
      "\n",
      "Final Directions ['Up', 'Up', 'Down', 'Up', 'Up', 'Left', 'Down', 'Up', 'Left', 'Left', 'Down', 'Down', 'Right']\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reactions = os.path.join(os.getcwd(), 'testing_set',\"ja00047a079_si_001_output\", 'images_with_boxes_dpi_100')\n",
    "list_reactions = sorted(os.listdir(reactions))\n",
    "diff_image2 = cv2.imread(os.path.join(reactions, list_reactions[2]))\n",
    "cons1 = pipeline(image = diff_image2, model = model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37643138],\n",
       "       [0.01702847],\n",
       "       [1.        ],\n",
       "       [0.99969375],\n",
       "       [0.00284655],\n",
       "       [0.3977585 ],\n",
       "       [0.00106351]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
